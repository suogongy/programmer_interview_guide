# å¤§è¯­è¨€æ¨¡å‹ - æ€»è§ˆ

## æ¦‚è¿°

å¤§è¯­è¨€æ¨¡å‹(LLM)æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡è¦çªç ´ï¼Œä»¥ChatGPTä¸ºä»£è¡¨çš„ç”Ÿæˆå¼AIæ­£åœ¨æ”¹å˜å„ä¸ªè¡Œä¸šã€‚æœ¬ç« èŠ‚æ·±å…¥ä»‹ç»LLMçš„åŸç†ã€åº”ç”¨å¼€å‘ã€Prompt Engineeringã€RAGç³»ç»Ÿè®¾è®¡ç­‰å‰æ²¿æŠ€æœ¯ã€‚

## ğŸ“š ç« èŠ‚å†…å®¹

### 1. [LLMåŸç†ä¸åº”ç”¨](./llm-fundamentals.md)
- **Transformeræ¶æ„**: æ³¨æ„åŠ›æœºåˆ¶ã€ç¼–ç å™¨-è§£ç å™¨
- **é¢„è®­ç»ƒæŠ€æœ¯**: è¯­è¨€å»ºæ¨¡ã€æ©ç è¯­è¨€æ¨¡å‹
- **å¾®è°ƒæ–¹æ³•**: æœ‰ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ å¾®è°ƒ
- **ä¸»æµæ¨¡å‹**: GPTç³»åˆ—ã€BERTç³»åˆ—ã€PaLMã€Claude

### 2. [Prompt Engineering](./prompt-engineering.md)
- **æç¤ºè¯è®¾è®¡**: é›¶æ ·æœ¬ã€å°‘æ ·æœ¬ã€æ€ç»´é“¾
- **æç¤ºè¯æ¨¡æ¿**: ç»“æ„åŒ–æç¤ºã€è§’è‰²æ‰®æ¼”
- **ä¼˜åŒ–æŠ€å·§**: è¿­ä»£æ”¹è¿›ã€A/Bæµ‹è¯•
- **å®‰å…¨è€ƒè™‘**: æç¤ºè¯æ³¨å…¥é˜²æŠ¤ã€å†…å®¹è¿‡æ»¤

### 3. [RAGç³»ç»Ÿè®¾è®¡](./rag-systems.md)
- **æ£€ç´¢å¢å¼ºç”Ÿæˆ**: RAGæ¶æ„åŸç†
- **å‘é‡æ•°æ®åº“**: Embeddingã€ç›¸ä¼¼åº¦æœç´¢
- **æ–‡æ¡£å¤„ç†**: åˆ†å—ç­–ç•¥ã€ç´¢å¼•æ„å»º
- **ç³»ç»Ÿé›†æˆ**: APIè®¾è®¡ã€æ€§èƒ½ä¼˜åŒ–

### 4. [AI Agentå¼€å‘](./ai-agents.md)
- **Agentæ¶æ„**: æ„ŸçŸ¥ã€å†³ç­–ã€æ‰§è¡Œ
- **å·¥å…·è°ƒç”¨**: Function Callingã€APIé›†æˆ
- **å¤šæ¨¡æ€èƒ½åŠ›**: æ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³å¤„ç†
- **å¯¹è¯ç³»ç»Ÿ**: ä¸Šä¸‹æ–‡ç®¡ç†ã€çŠ¶æ€è·Ÿè¸ª

### 5. [å‘é‡æ•°æ®åº“](./vector-databases.md)
- **å‘é‡å­˜å‚¨**: é«˜ç»´å‘é‡ç´¢å¼•ã€ANNç®—æ³•
- **ç›¸ä¼¼åº¦è®¡ç®—**: ä½™å¼¦ç›¸ä¼¼åº¦ã€æ¬§å¼è·ç¦»
- **æ•°æ®åº“é€‰å‹**: Pineconeã€Weaviateã€Milvus
- **æ€§èƒ½ä¼˜åŒ–**: ç´¢å¼•ç­–ç•¥ã€æŸ¥è¯¢ä¼˜åŒ–

## ğŸ¯ LLMæŠ€æœ¯æ ˆå¯¹æ¯”

### ä¸»æµLLMæ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | è®­ç»ƒæ•°æ® | ä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ |
|------|--------|----------|------|---------|
| **GPT-4** | ~1.7T | ç½‘ç»œæ–‡æœ¬ | é€šç”¨èƒ½åŠ›å¼ºã€æ¨ç†èƒ½åŠ›ä¼˜ç§€ | é€šç”¨å¯¹è¯ã€å¤æ‚æ¨ç† |
| **Claude-3** | æœªå…¬å¼€ | é«˜è´¨é‡æ•°æ® | å®‰å…¨æ€§å¥½ã€é•¿æ–‡æœ¬å¤„ç† | æ–‡æ¡£åˆ†æã€ä»£ç ç”Ÿæˆ |
| **Gemini Pro** | æœªå…¬å¼€ | å¤šæ¨¡æ€æ•°æ® | å¤šæ¨¡æ€èƒ½åŠ›ã€Googleç”Ÿæ€ | å¤šæ¨¡æ€åº”ç”¨ |
| **æ–‡å¿ƒä¸€è¨€** | æœªå…¬å¼€ | ä¸­æ–‡æ•°æ® | ä¸­æ–‡ç†è§£å¥½ã€åˆè§„æ€§å¼º | ä¸­æ–‡åº”ç”¨ã€ä¼ä¸šåœºæ™¯ |

### å¼€æºLLMå¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | è®¸å¯è¯ | ç‰¹ç‚¹ | éƒ¨ç½²éš¾åº¦ |
|------|--------|--------|------|---------|
| **Llama-2** | 7B-70B | è‡ªå®šä¹‰ | Metaå¼€æºã€æ€§èƒ½ä¼˜ç§€ | ä¸­ç­‰ |
| **Mistral** | 7B-8x7B | Apache 2.0 | æ¬§æ´²å¼€æºã€é«˜æ•ˆè®­ç»ƒ | ä¸­ç­‰ |
| **Qwen** | 7B-72B | è‡ªå®šä¹‰ | é˜¿é‡Œå¼€æºã€ä¸­æ–‡ä¼˜åŒ– | ä¸­ç­‰ |
| **ChatGLM** | 6B-130B | è‡ªå®šä¹‰ | æ¸…åå¼€æºã€å¯¹è¯ä¼˜åŒ– | ç®€å• |

## ğŸ§  æ ¸å¿ƒæŠ€æœ¯å®ç°

### Prompt Engineeringå®è·µ

#### åŸºç¡€æç¤ºè¯æ¨¡æ¿
```python
def create_basic_prompt(task, context, examples=""):
    prompt = f"""
ä»»åŠ¡: {task}

{examples}

ä¸Šä¸‹æ–‡: {context}

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å®Œæˆä»»åŠ¡:
1. ä»”ç»†åˆ†æé—®é¢˜
2. æä¾›è¯¦ç»†çš„è§£å†³æ–¹æ¡ˆ
3. è§£é‡Šä½ çš„æ¨ç†è¿‡ç¨‹

å›ç­”:
"""
    return prompt

# ä½¿ç”¨ç¤ºä¾‹
task = "ä»£ç å®¡æŸ¥"
context = "Pythonå‡½æ•°å®ç°äºŒåˆ†æœç´¢"
examples = """
ç¤ºä¾‹è¾“å…¥: def binary_search(arr, target): ...
ç¤ºä¾‹è¾“å‡º: ä»£ç é€»è¾‘æ­£ç¡®ï¼Œå»ºè®®æ·»åŠ è¾¹ç•Œæ£€æŸ¥...
"""

prompt = create_basic_prompt(task, context, examples)
```

#### æ€ç»´é“¾æç¤º(Chain of Thought)
```python
def chain_of_thought_prompt(problem):
    prompt = f"""
é—®é¢˜: {problem}

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è§£å†³é—®é¢˜:

æ­¥éª¤1: ç†è§£é—®é¢˜
- è¯†åˆ«å…³é”®ä¿¡æ¯
- ç¡®å®šé—®é¢˜ç±»å‹
- æ˜ç¡®æ±‚è§£ç›®æ ‡

æ­¥éª¤2: åˆ†æç­–ç•¥
- åˆ—å‡ºå¯èƒ½çš„è§£å†³æ–¹æ³•
- æ¯”è¾ƒå„æ–¹æ³•çš„ä¼˜ç¼ºç‚¹
- é€‰æ‹©æœ€åˆé€‚çš„æ–¹æ³•

æ­¥éª¤3: æ‰§è¡Œè®¡ç®—
- è¯¦ç»†å±•ç¤ºè®¡ç®—è¿‡ç¨‹
- æ£€æŸ¥ä¸­é—´ç»“æœ
- éªŒè¯æœ€ç»ˆç­”æ¡ˆ

æ­¥éª¤4: æ€»ç»“å›ç­”
- ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
- è§£é‡Šè§£é¢˜æ€è·¯
- æåŠæ³¨æ„äº‹é¡¹

å¼€å§‹è§£ç­”:
"""
    return prompt
```

### RAGç³»ç»Ÿå®ç°

#### æ–‡æ¡£å¤„ç†å’Œå‘é‡åŒ–
```python
import openai
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

class RAGSystem:
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        self.encoder = SentenceTransformer(model_name)
        self.index = None
        self.documents = []
        
    def add_documents(self, docs):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        # æ–‡æ¡£åˆ†å—
        chunks = []
        for doc in docs:
            chunks.extend(self.chunk_document(doc))
        
        # ç”Ÿæˆå‘é‡
        embeddings = self.encoder.encode(chunks)
        
        # æ„å»ºFAISSç´¢å¼•
        if self.index is None:
            dimension = embeddings.shape[1]
            self.index = faiss.IndexFlatIP(dimension)
        
        # å½’ä¸€åŒ–å‘é‡
        faiss.normalize_L2(embeddings)
        self.index.add(embeddings.astype('float32'))
        self.documents.extend(chunks)
    
    def chunk_document(self, doc, chunk_size=500, overlap=50):
        """æ–‡æ¡£åˆ†å—ç­–ç•¥"""
        chunks = []
        words = doc.split()
        
        for i in range(0, len(words), chunk_size - overlap):
            chunk = ' '.join(words[i:i + chunk_size])
            chunks.append(chunk)
            
        return chunks
    
    def retrieve(self, query, k=5):
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        query_embedding = self.encoder.encode([query])
        faiss.normalize_L2(query_embedding)
        
        scores, indices = self.index.search(
            query_embedding.astype('float32'), k
        )
        
        results = []
        for score, idx in zip(scores[0], indices[0]):
            results.append({
                'document': self.documents[idx],
                'score': float(score)
            })
        
        return results
    
    def generate_answer(self, query, retrieved_docs):
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
        context = "\n".join([doc['document'] for doc in retrieved_docs])
        
        prompt = f"""
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜:

ä¸Šä¸‹æ–‡:
{context}

é—®é¢˜: {query}

è¯·åŸºäºä¸Šä¸‹æ–‡å†…å®¹å›ç­”ï¼Œå¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜æ— æ³•åŸºäºç»™å®šä¿¡æ¯å›ç­”ã€‚

å›ç­”:
"""
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        return response.choices[0].message.content
    
    def query(self, question, k=5):
        """å®Œæ•´çš„RAGæŸ¥è¯¢æµç¨‹"""
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retrieved_docs = self.retrieve(question, k)
        
        # 2. ç”Ÿæˆç­”æ¡ˆ
        answer = self.generate_answer(question, retrieved_docs)
        
        return {
            'answer': answer,
            'sources': retrieved_docs
        }
```

### AI Agentæ¶æ„

#### ç®€å•Agentå®ç°
```python
import json
from typing import List, Dict, Any

class SimpleAgent:
    def __init__(self, llm_client, tools):
        self.llm = llm_client
        self.tools = {tool.name: tool for tool in tools}
        self.conversation_history = []
    
    def think(self, user_input: str) -> Dict[str, Any]:
        """Agentæ€è€ƒè¿‡ç¨‹"""
        prompt = self.create_thinking_prompt(user_input)
        
        response = self.llm.chat_completion(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        try:
            thinking = json.loads(response)
            return thinking
        except:
            return {"action": "respond", "content": response}
    
    def create_thinking_prompt(self, user_input: str) -> str:
        available_tools = list(self.tools.keys())
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œéœ€è¦å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚

å¯ç”¨å·¥å…·: {available_tools}

ç”¨æˆ·è¾“å…¥: {user_input}

è¯·åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œå†³å®šé‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ã€‚ä»¥JSONæ ¼å¼å›ç­”:

å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·:
{{
    "action": "use_tool",
    "tool": "å·¥å…·åç§°",
    "parameters": {{"å‚æ•°å": "å‚æ•°å€¼"}}
}}

å¦‚æœå¯ä»¥ç›´æ¥å›ç­”:
{{
    "action": "respond",
    "content": "å›ç­”å†…å®¹"
}}

å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯:
{{
    "action": "ask",
    "question": "éœ€è¦è¯¢é—®çš„é—®é¢˜"
}}

åˆ†æ:
"""
        return prompt
    
    def execute_action(self, thinking: Dict[str, Any]) -> str:
        """æ‰§è¡Œå†³ç­–"""
        action = thinking.get("action")
        
        if action == "use_tool":
            tool_name = thinking.get("tool")
            parameters = thinking.get("parameters", {})
            
            if tool_name in self.tools:
                result = self.tools[tool_name].execute(**parameters)
                return f"å·¥å…·æ‰§è¡Œç»“æœ: {result}"
            else:
                return f"å·¥å…· {tool_name} ä¸å­˜åœ¨"
        
        elif action == "respond":
            return thinking.get("content", "")
        
        elif action == "ask":
            return thinking.get("question", "éœ€è¦æ›´å¤šä¿¡æ¯")
        
        else:
            return "æœªçŸ¥æ“ä½œ"
    
    def process(self, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # è®°å½•å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "user", 
            "content": user_input
        })
        
        # æ€è€ƒå’Œæ‰§è¡Œ
        thinking = self.think(user_input)
        response = self.execute_action(thinking)
        
        # è®°å½•å›ç­”
        self.conversation_history.append({
            "role": "assistant", 
            "content": response
        })
        
        return response

# å·¥å…·å®šä¹‰ç¤ºä¾‹
class WeatherTool:
    name = "get_weather"
    
    def execute(self, location: str) -> str:
        # æ¨¡æ‹Ÿå¤©æ°”APIè°ƒç”¨
        return f"{location}çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œæ¸©åº¦25Â°C"

class CalculatorTool:
    name = "calculate"
    
    def execute(self, expression: str) -> str:
        try:
            result = eval(expression)  # ç”Ÿäº§ç¯å¢ƒéœ€è¦å®‰å…¨çš„è¡¨è¾¾å¼æ±‚å€¼
            return str(result)
        except:
            return "è®¡ç®—é”™è¯¯"
```

## ğŸ”¥ å®é™…åº”ç”¨åœºæ™¯

### 1. æ™ºèƒ½å®¢æœç³»ç»Ÿ

#### ç³»ç»Ÿæ¶æ„
```python
class CustomerServiceBot:
    def __init__(self):
        self.rag_system = RAGSystem()
        self.intent_classifier = IntentClassifier()
        self.knowledge_base = self.load_knowledge_base()
        
    def process_query(self, user_query, user_context=None):
        # 1. æ„å›¾è¯†åˆ«
        intent = self.intent_classifier.classify(user_query)
        
        # 2. å®ä½“æŠ½å–
        entities = self.extract_entities(user_query)
        
        # 3. æ ¹æ®æ„å›¾å¤„ç†
        if intent == "product_inquiry":
            return self.handle_product_inquiry(user_query, entities)
        elif intent == "technical_support":
            return self.handle_technical_support(user_query, entities)
        elif intent == "complaint":
            return self.handle_complaint(user_query, entities)
        else:
            return self.handle_general_query(user_query)
    
    def handle_product_inquiry(self, query, entities):
        # ä½¿ç”¨RAGæ£€ç´¢äº§å“ä¿¡æ¯
        results = self.rag_system.query(query)
        return self.format_product_response(results)
```

### 2. ä»£ç åŠ©æ‰‹

#### ä»£ç ç”Ÿæˆå’Œè§£é‡Š
```python
class CodeAssistant:
    def __init__(self, llm_client):
        self.llm = llm_client
        
    def generate_code(self, requirement, language="python"):
        prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚ç”Ÿæˆ{language}ä»£ç :

éœ€æ±‚: {requirement}

è¦æ±‚:
1. ä»£ç è¦æœ‰é€‚å½“çš„æ³¨é‡Š
2. è€ƒè™‘è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†
3. éµå¾ªæœ€ä½³å®è·µ
4. æä¾›ä½¿ç”¨ç¤ºä¾‹

ä»£ç :
```{language}
"""
        
        response = self.llm.chat_completion(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        return response
    
    def explain_code(self, code, language="python"):
        prompt = f"""
è¯·è§£é‡Šä»¥ä¸‹{language}ä»£ç çš„åŠŸèƒ½:

```{language}
{code}
```

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è§£é‡Š:
1. ä»£ç æ•´ä½“åŠŸèƒ½
2. ä¸»è¦é€»è¾‘æ­¥éª¤
3. å…³é”®æŠ€æœ¯ç‚¹
4. å¯èƒ½çš„æ”¹è¿›å»ºè®®

è§£é‡Š:
"""
        
        response = self.llm.chat_completion(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        return response
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### æ¨¡å‹æ¨ç†ä¼˜åŒ–
1. **æ¨¡å‹é‡åŒ–**: INT8/INT4é‡åŒ–å‡å°‘å†…å­˜å ç”¨
2. **æ¨¡å‹å‰ªæ**: ç§»é™¤ä¸é‡è¦çš„æƒé‡å‚æ•°
3. **çŸ¥è¯†è’¸é¦**: ç”¨å°æ¨¡å‹å­¦ä¹ å¤§æ¨¡å‹çŸ¥è¯†
4. **æ‰¹å¤„ç†**: æ‰¹é‡å¤„ç†è¯·æ±‚æé«˜ååé‡

### ç³»ç»Ÿæ¶æ„ä¼˜åŒ–
1. **ç¼“å­˜ç­–ç•¥**: ç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœ
2. **è´Ÿè½½å‡è¡¡**: åˆ†å¸ƒå¼éƒ¨ç½²æé«˜å¯ç”¨æ€§
3. **å¼‚æ­¥å¤„ç†**: éé˜»å¡è¯·æ±‚å¤„ç†
4. **èµ„æºç®¡ç†**: GPUèµ„æºè°ƒåº¦ä¼˜åŒ–

## ğŸ”’ å®‰å…¨ä¸ä¼¦ç†è€ƒè™‘

### æç¤ºè¯æ³¨å…¥é˜²æŠ¤
```python
def sanitize_prompt(user_input):
    """æç¤ºè¯å®‰å…¨æ£€æŸ¥"""
    # æ£€æŸ¥æ¶æ„æŒ‡ä»¤
    malicious_patterns = [
        "ignore previous instructions",
        "disregard the above",
        "override system prompt",
        "act as if you are"
    ]
    
    user_input_lower = user_input.lower()
    for pattern in malicious_patterns:
        if pattern in user_input_lower:
            return "æ£€æµ‹åˆ°æ½œåœ¨çš„æ¶æ„è¾“å…¥ï¼Œè¯·é‡æ–°è¾“å…¥æ­£å¸¸é—®é¢˜ã€‚"
    
    return user_input

def content_filter(response):
    """å†…å®¹è¿‡æ»¤"""
    # æ£€æŸ¥ä¸å½“å†…å®¹
    if contains_inappropriate_content(response):
        return "æŠ±æ­‰ï¼Œæˆ‘ä¸èƒ½æä¾›è¿™ç±»ä¿¡æ¯ã€‚"
    
    return response
```

### æ•°æ®éšç§ä¿æŠ¤
1. **æ•°æ®è„±æ•**: æ•æ„Ÿä¿¡æ¯åŒ¿ååŒ–å¤„ç†
2. **è®¿é—®æ§åˆ¶**: é™åˆ¶æ¨¡å‹è®¿é—®æƒé™
3. **å®¡è®¡æ—¥å¿—**: è®°å½•æ‰€æœ‰äº¤äº’æ—¥å¿—
4. **åˆè§„æ€§**: éµå®ˆGDPRã€CCPAç­‰æ³•è§„

## ğŸ“ é¢è¯•é‡ç‚¹

### LLMåŸç†
1. **Transformeræ¶æ„**: æ³¨æ„åŠ›æœºåˆ¶ã€ä½ç½®ç¼–ç 
2. **é¢„è®­ç»ƒæŠ€æœ¯**: è‡ªç›‘ç£å­¦ä¹ ã€è¯­è¨€å»ºæ¨¡
3. **å¾®è°ƒæ–¹æ³•**: LoRAã€Prefix Tuningã€P-Tuning
4. **è¯„ä¼°æŒ‡æ ‡**: BLEUã€ROUGEã€äººå·¥è¯„ä¼°

### åº”ç”¨å¼€å‘
1. **Prompt Engineering**: æç¤ºè¯è®¾è®¡æŠ€å·§
2. **RAGç³»ç»Ÿ**: æ£€ç´¢å¢å¼ºç”Ÿæˆæ¶æ„
3. **Agentå¼€å‘**: å·¥å…·è°ƒç”¨ã€å¤šè½®å¯¹è¯
4. **æ€§èƒ½ä¼˜åŒ–**: æ¨ç†åŠ é€Ÿã€æˆæœ¬æ§åˆ¶

### å·¥ç¨‹å®è·µ
1. **æ¨¡å‹éƒ¨ç½²**: æœåŠ¡åŒ–ã€å®¹å™¨åŒ–éƒ¨ç½²
2. **ç›‘æ§è¿ç»´**: æ€§èƒ½ç›‘æ§ã€å¼‚å¸¸å¤„ç†
3. **å®‰å…¨è€ƒè™‘**: å†…å®¹å®‰å…¨ã€æ•°æ®éšç§
4. **æˆæœ¬ä¼˜åŒ–**: æ¨¡å‹é€‰æ‹©ã€è°ƒç”¨ç­–ç•¥

## ğŸ“– å­¦ä¹ èµ„æº

### è®ºæ–‡æ¨è
1. **Attention Is All You Need** - TransformeråŸç†
2. **BERT** - åŒå‘ç¼–ç å™¨è¡¨ç¤º
3. **GPTç³»åˆ—** - ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹
4. **RAG** - æ£€ç´¢å¢å¼ºç”Ÿæˆ

### å¼€æºé¡¹ç›®
1. [Transformers](https://github.com/huggingface/transformers) - Hugging Faceæ¨¡å‹åº“
2. [LangChain](https://github.com/langchain-ai/langchain) - LLMåº”ç”¨å¼€å‘æ¡†æ¶
3. [LlamaIndex](https://github.com/run-llama/llama_index) - æ•°æ®æ¡†æ¶
4. [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) - è‡ªä¸»AIä»£ç†

### å­¦ä¹ å¹³å°
1. [OpenAI Cookbook](https://github.com/openai/openai-cookbook) - å®˜æ–¹ç¤ºä¾‹
2. [Deep Learning AI](https://www.deeplearning.ai/) - åœ¨çº¿è¯¾ç¨‹
3. [Hugging Face Course](https://huggingface.co/course) - å…è´¹è¯¾ç¨‹

---

å¤§è¯­è¨€æ¨¡å‹æ­£åœ¨é‡å¡‘äººå·¥æ™ºèƒ½åº”ç”¨ï¼ŒæŒæ¡LLMæŠ€æœ¯å°†ä¸ºæ‚¨çš„èŒä¸šå‘å±•å¸¦æ¥å·¨å¤§ä¼˜åŠ¿ã€‚ 